{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NWS Forecast Data\n",
    "The NWS doesn't store historical forecast data, so this notebook will just be for prototyping the scraping functions for the DAG (i.e., no preliminary scrape and data load as with the USCRN data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Time Libraries\n",
    "import datetime as dt \n",
    "import pytz\n",
    "from tzwhere import tzwhere "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's save the relevant urls for each station location -- this will make it easier when we're retrieving the results for each station as part of our DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrl(row):\n",
    "  \"\"\"Construct NWS forecast url from latitude and longitude columns\"\"\"\n",
    "  url = f\"https://forecast.weather.gov/MapClick.php?lat={row['latitude']}&lon={row['longitude']}&unit=0&lg=english&FcstType=digital&menu=1\"\n",
    "  return url\n",
    "\n",
    "locations = pd.read_csv(\"data/locations.csv\")\n",
    "locations['nws_url'] = locations.apply(getUrl, axis=1)\n",
    "locations.to_csv(\"data/locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/deb-projects/team-week3/venv/lib/python3.7/site-packages/tzwhere/tzwhere.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.timezoneNamesToPolygons[tzname] = WRAP(polys)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      America/Anchorage\n",
       "1      America/Anchorage\n",
       "2          America/Sitka\n",
       "3           America/Nome\n",
       "4      America/Anchorage\n",
       "5      America/Anchorage\n",
       "6      America/Anchorage\n",
       "7           America/Nome\n",
       "8      America/Anchorage\n",
       "9         America/Juneau\n",
       "10     America/Anchorage\n",
       "11    America/Metlakatla\n",
       "12     America/Anchorage\n",
       "13     America/Anchorage\n",
       "14     America/Anchorage\n",
       "15     America/Anchorage\n",
       "16     America/Anchorage\n",
       "17     America/Anchorage\n",
       "18       America/Yakutat\n",
       "19     America/Anchorage\n",
       "20     America/Anchorage\n",
       "21          America/Nome\n",
       "22     America/Anchorage\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tzwhere import tzwhere\n",
    "\n",
    "# tzw = tzwhere.tzwhere()\n",
    "\n",
    "# def local_time(row): \n",
    "#   return tzw.tzNameAt(row['latitude'], row['longitude'])\n",
    "  \n",
    "# locations.apply(local_time, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototyping \n",
    "Let's scrape the tabular data from one of the NWS pages and transform it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45470 656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour (AKST)</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Dewpoint (°F)</th>\n",
       "      <th>Wind Chill (°F)</th>\n",
       "      <th>Surface Wind (mph)</th>\n",
       "      <th>Wind Dir</th>\n",
       "      <th>Gust</th>\n",
       "      <th>Sky Cover (%)</th>\n",
       "      <th>Precipitation Potential (%)</th>\n",
       "      <th>Relative Humidity (%)</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Freezing Rain</th>\n",
       "      <th>Sleet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>02/16</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>NE</td>\n",
       "      <td></td>\n",
       "      <td>74</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Chc</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02/16</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td>92</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Chc</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>02/17</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>S</td>\n",
       "      <td></td>\n",
       "      <td>96</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Ocnl</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>02/16</td>\n",
       "      <td>06</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SW</td>\n",
       "      <td></td>\n",
       "      <td>86</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Chc</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/15</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td></td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date Hour (AKST) Temperature (°F) Dewpoint (°F) Wind Chill (°F)  \\\n",
       "26  02/16          18               26            20              20   \n",
       "11  02/16          03                2            -4               2   \n",
       "42  02/17          10               23            19              14   \n",
       "14  02/16          06                2            -4               2   \n",
       "4   02/15          20                9             3               9   \n",
       "\n",
       "   Surface Wind (mph) Wind Dir Gust Sky Cover (%) Precipitation Potential (%)  \\\n",
       "26                  5       NE                 74                          46   \n",
       "11                  1        E                 92                          37   \n",
       "42                  7        S                 96                          82   \n",
       "14                  0       SW                 86                          45   \n",
       "4                   1       NW                 34                           1   \n",
       "\n",
       "   Relative Humidity (%) Rain Thunder  Snow Freezing Rain Sleet  \n",
       "26                    79   --      --   Chc            --    --  \n",
       "11                    75   --      --   Chc            --    --  \n",
       "42                    85   --      --  Ocnl            --    --  \n",
       "14                    76   --      --   Chc            --    --  \n",
       "4                     77   --      --    --            --    --  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "url = requests.get(choice(list(locations['nws_url'])))\n",
    "soup = BeautifulSoup(url.content, \"html.parser\")\n",
    "\n",
    "tables = soup.find_all('table')\n",
    "data = tables[5].find_all(\"tr\")\n",
    "\n",
    "# Data tables are divided with colspan elements\n",
    "colspan = data[0]\n",
    "indices = [i for i, x in enumerate(data) if x == colspan]\n",
    "\n",
    "dt1 = data[indices[0]+1:indices[1]] # first 24hrs\n",
    "dt2 = data[indices[1]+1:] # next 24hrs\n",
    "\n",
    "# Combining these into one dataframe\n",
    "def getDF(l1, l2): \n",
    "\n",
    "  ls = l1.copy()\n",
    "  ls.extend(l2)\n",
    "\n",
    "  data_map = {}\n",
    "\n",
    "  for ele in ls:\n",
    "    row = [x.getText() for x in ele.find_all(\"font\")]\n",
    "\n",
    "    if row[0] not in data_map.keys(): # elements from l1\n",
    "      data_map[row[0]] = row[1:]\n",
    "    else: # elements from l2\n",
    "      data_map[row[0]].extend(row[1:])\n",
    "\n",
    "  df = pd.DataFrame(data_map)\n",
    "  df['Date'][df['Date']==\"\"] = np.NaN\n",
    "  df['Date'].ffill(inplace=True)\n",
    "\n",
    "  print(sys.getsizeof(df), sys.getsizeof(df.to_dict())) \n",
    "  return df\n",
    "\n",
    "getDF(dt1, dt2).sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the size penalty you get from representing data as a dataframe versus a simpler data type like a dictionary. We'll keep this in mind when we refactor our code next. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Old Refactor\n",
    "\n",
    "# def getDict(lists:list):  # Refactoring from getDF to process all the tables, not just two\n",
    "#   \"\"\"Unnest list of tabular data and combine into one dictionary\"\"\" \n",
    "#   ls = list(itertools.chain.from_iterable(lists)) # Unnest lists \n",
    "#   # Note: each list in lists needs to have a field inserted for station_location prior to being fed into this function\n",
    "#   data_map = {}\n",
    "#   for ele in ls:\n",
    "#     row = [x.getText() for x in ele.find_all(\"font\")]\n",
    "#     if row[0] not in data_map.keys(): # elements from l1\n",
    "#       data_map[row[0]] = row[1:]\n",
    "#     else: # elements from l2\n",
    "#       data_map[row[0]].extend(row[1:])\n",
    "\n",
    "#   data_map['Date'] = ffList(data_map['Date'])\n",
    "\n",
    "#   return data_map\n",
    "\n",
    "\n",
    "# def getForecast():\n",
    "#   \"\"\"Get data from soup objects created from NWS urls in locations.csv, then write to .csv\"\"\"\n",
    " \n",
    "#   locations = pd.read_csv(\"data/locations.csv\")\n",
    "#   loc_dict = dict(zip(locations['station_location'], locations['nws_url']))\n",
    "  \n",
    "#   ls = []\n",
    "#   for station, url in loc_dict.items():\n",
    "#     result = requests.get(url)\n",
    "#     soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "#     data = soup.find_all(\"table\")[5].find_all(\"tr\")\n",
    "\n",
    "#     # 'data' is divided into two tables by two colspan elements\n",
    "#     colspan = data[0]\n",
    "#     data = [x for  x in data if x != colspan] # add station_name here \n",
    "#     ls.append(data)\n",
    "\n",
    "#   return getDict(ls)\n",
    "# # pd.DataFrame(getForecast())  \n",
    "\n",
    "# pd.DataFrame(getForecast())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffList(ls:list) -> list:\n",
    "  \"\"\"Like ffill() from pandas, except for lists\"\"\"\n",
    "  for i in range(len(ls)):\n",
    "    if not ls[i] and i > 0:\n",
    "        ls[i] = ls[i-1]\n",
    "  return ls\n",
    "\n",
    "def getColsFromTable(table:list, location:str):\n",
    "  \"\"\"Get cols from list of <tr> elements\"\"\"\n",
    "  cols = [[ele.getText() for ele in tr.find_all(\"font\")] for tr in table] # these are rows in the table's current landscape orientation\n",
    "  location_col = ['location']\n",
    "  location_col.extend([location]*24)\n",
    "  cols.insert(1, location_col)\n",
    "  cols.insert(19, location_col) # for second table\n",
    "  return cols\n",
    "\n",
    "def getDict(col_list:list):\n",
    "  \"\"\"Get dictionary from list of columns (which are also lists)\"\"\"\n",
    "  data_map = {}\n",
    "  for col in col_list:\n",
    "    if col[0] not in data_map.keys(): # cols from first half of table\n",
    "      data_map[col[0]] = col[1:]\n",
    "    else: # cols from second half\n",
    "      data_map[col[0]].extend(col[1:])\n",
    "  data_map['Date'] = ffList(data_map['Date'])\n",
    "  return data_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nws_dag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForecast():\n",
    "  \"\"\"Get dictionary of forecast data for next 48 hours from various points in Alaska\"\"\"\n",
    "  locations = pd.read_csv(\"data/locations.csv\")\n",
    "  loc_dict = dict(zip(locations['station_location'], locations['nws_url']))\n",
    "\n",
    "  col_list = []\n",
    "  for location, url in loc_dict.items():\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "    table48 = soup.find_all(\"table\")[5].find_all(\"tr\") # list of <tr> elements from main data table (really two tables combined: one for each day in next 48h period)\n",
    "    colspan = table48[0]  # divided into two tables by two colspan elements\n",
    "    table48 = [tr for  tr in table48 if tr != colspan] # remove colspan elements\n",
    "\n",
    "    cols = getColsFromTable(table48,location)    \n",
    "    col_list.extend(cols)\n",
    "  \n",
    "  return getDict(col_list)\n",
    "\n",
    "# def transformDF(myDict): \n",
    "#   \"\"\"Cast dictionary from getForecast() to a dataframe, transform, and write (append) to .csv\"\"\"\n",
    "#   # We want to write to .csv instead of just uploading to BigQuery because NWS does not store their forecast data.\n",
    "#   # So it's a good idea to keep a local backup in case we screw up our BigQuery table, or vice versa. \n",
    "\n",
    "\n",
    "# def uploadCSV():\n",
    "#   \"\"\"Upload .csv created by transformDF() to BigQuery\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = getForecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(test_dict)\n",
    "tdf.columns = [col.lower() for col in tdf.columns] \n",
    "uscrn = pd.read_csv(\"data/uscrn.csv\", skiprows=list(range(2,2100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_location</th>\n",
       "      <th>wbanno</th>\n",
       "      <th>utc_date</th>\n",
       "      <th>utc_time</th>\n",
       "      <th>lst_date</th>\n",
       "      <th>lst_time</th>\n",
       "      <th>crx_vn</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>t_calc</th>\n",
       "      <th>...</th>\n",
       "      <th>solarad_min_flag</th>\n",
       "      <th>sur_temp_type</th>\n",
       "      <th>sur_temp</th>\n",
       "      <th>sur_temp_flag</th>\n",
       "      <th>sur_temp_max</th>\n",
       "      <th>sur_temp_max_flag</th>\n",
       "      <th>sur_temp_min</th>\n",
       "      <th>sur_temp_min_flag</th>\n",
       "      <th>rh_hr_avg</th>\n",
       "      <th>rh_hr_avg_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54784</th>\n",
       "      <td>Sand_Point</td>\n",
       "      <td>25630</td>\n",
       "      <td>20230202</td>\n",
       "      <td>2100</td>\n",
       "      <td>20230202</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.424</td>\n",
       "      <td>-160.47</td>\n",
       "      <td>55.35</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>Tok</td>\n",
       "      <td>96404</td>\n",
       "      <td>20220831</td>\n",
       "      <td>2300</td>\n",
       "      <td>20220831</td>\n",
       "      <td>1400</td>\n",
       "      <td>2.514</td>\n",
       "      <td>-141.21</td>\n",
       "      <td>62.74</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_location  wbanno  utc_date  utc_time  lst_date  lst_time  \\\n",
       "54784       Sand_Point   25630  20230202      2100  20230202      1200   \n",
       "8012               Tok   96404  20220831      2300  20220831      1400   \n",
       "\n",
       "       crx_vn  longitude  latitude  t_calc  ...  solarad_min_flag  \\\n",
       "54784   2.424    -160.47     55.35     1.8  ...                 0   \n",
       "8012    2.514    -141.21     62.74    18.4  ...                 0   \n",
       "\n",
       "       sur_temp_type  sur_temp  sur_temp_flag  sur_temp_max  \\\n",
       "54784              C       1.5              0           3.1   \n",
       "8012               C      23.8              0          26.4   \n",
       "\n",
       "       sur_temp_max_flag  sur_temp_min  sur_temp_min_flag  rh_hr_avg  \\\n",
       "54784                  0           1.0                  0      -9999   \n",
       "8012                   0          22.0                  0         36   \n",
       "\n",
       "       rh_hr_avg_flag  \n",
       "54784               0  \n",
       "8012                0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscrn.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>hour (akst)</th>\n",
       "      <th>temperature (°f)</th>\n",
       "      <th>dewpoint (°f)</th>\n",
       "      <th>wind chill (°f)</th>\n",
       "      <th>surface wind (mph)</th>\n",
       "      <th>wind dir</th>\n",
       "      <th>gust</th>\n",
       "      <th>sky cover (%)</th>\n",
       "      <th>precipitation potential (%)</th>\n",
       "      <th>relative humidity (%)</th>\n",
       "      <th>rain</th>\n",
       "      <th>thunder</th>\n",
       "      <th>snow</th>\n",
       "      <th>freezing rain</th>\n",
       "      <th>sleet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/16</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Chc</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/16</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Chc</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date   location hour (akst) temperature (°f) dewpoint (°f)  \\\n",
       "0  02/16  Fairbanks          12                7            -2   \n",
       "1  02/16  Fairbanks          13                9             0   \n",
       "\n",
       "  wind chill (°f) surface wind (mph) wind dir gust sky cover (%)  \\\n",
       "0              -2                  5        E                 92   \n",
       "1               0                  5        E                 92   \n",
       "\n",
       "  precipitation potential (%) relative humidity (%) rain thunder snow  \\\n",
       "0                          30                    66   --      --  Chc   \n",
       "1                          30                    66   --      --  Chc   \n",
       "\n",
       "  freezing rain sleet  \n",
       "0            --    --  \n",
       "1            --    --  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     20230216\n",
       "12    20230217\n",
       "36    20230218\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "# 1.) Add year to date column \n",
    "# 2.) Format 'date' (YYYYMMDD) to match lst_date\n",
    "cur_year = date.strftime(date.today(), \"%Y\")\n",
    "\n",
    "def date_str(d):\n",
    "  d = re.sub(\"/\",\"\", d)\n",
    "  return f\"{cur_year}{d}\"\n",
    "tdf['date'] = tdf['date'].map(date_str)\n",
    "\n",
    "tdf['date'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1300\n",
      "1    1900\n",
      "Name: lst_time, dtype: int64\n",
      "9     21\n",
      "16    04\n",
      "Name: hour (akst), dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3.) Format 'hour (akst)' to match 'lst_time' (HH00 -- no leading 0 for hour)\n",
    "print(uscrn['lst_time'].iloc[0:2])\n",
    "print(tdf['hour (akst)'].drop_duplicates().sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2002-08-09\n",
       "1       2022-10-02\n",
       "2       2022-10-02\n",
       "3       2022-10-02\n",
       "4       2022-10-02\n",
       "           ...    \n",
       "62940   2023-02-16\n",
       "62941   2023-02-16\n",
       "62942   2023-02-16\n",
       "62943   2023-02-16\n",
       "62944   2023-02-16\n",
       "Name: utc_date, Length: 62945, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(uscrn['utc_date'], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.) Calculate UTC datetime from date and hour columns \n",
    "\n",
    "# # find tz string: [tz for tz in pytz.all_timezones if tz.find(\"Alaska\") != -1]\n",
    "# tz = pytz.timezone('US/Alaska') \n",
    "\n",
    "\n",
    "# def dateUTC(row): \n",
    "#   dt = datetime.strptime(row, \"%m/%d/%y\")\n",
    "#   tz.utcoffset(dt)\n",
    "\n",
    "\n",
    "\n",
    "# tdf['date_hour'] = date_hour.map(dateUTC)\n",
    "# 5.) Split UTC datetime into 'utc_date' and 'utc_time' columns, matching formatting (YYYYMMDD and HHmm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Dec  7 2022, 01:12:33) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8b552aa03fd1a84f75da23b88ec62cd47e7b74ff6fa717b01373b8fb12f71a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
